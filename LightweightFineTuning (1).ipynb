{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22de1d39cb7a46a4b074b4ac572d294a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 3.11M/3.11M [00:00<00:00, 9.67MB/s]\n",
      "Downloading data: 100%|██████████| 72.8k/72.8k [00:00<00:00, 521kB/s]\n",
      "Downloading data: 100%|██████████| 148k/148k [00:00<00:00, 489kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b530ae6ff5407d86393c8e8138a2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547e25d1c71a4636aaba2d017bb8cb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a182a3da8254a08bc8cb40a1fe8e9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['sentence', 'label', 'idx'],\n",
       "     num_rows: 67349\n",
       " }),\n",
       " 'validation': Dataset({\n",
       "     features: ['sentence', 'label', 'idx'],\n",
       "     num_rows: 872\n",
       " })}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = ['train','validation']\n",
    "ds = {split: ds for split, ds in zip(splits, load_dataset('glue','sst2', split = splits))}\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895b7d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3eaa92a37c747ab9b9ccd844a476e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589dbb00161e418493d9fafef9faadb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['sentence', 'label', 'idx'],\n",
       "     num_rows: 67349\n",
       " }),\n",
       " 'validation': Dataset({\n",
       "     features: ['sentence', 'label', 'idx'],\n",
       "     num_rows: 872\n",
       " })}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate labels in the dataset and keep only valid ones\n",
    "valid_ds = {}\n",
    "for split in splits:\n",
    "    valid_ds[split] = ds[split].filter(lambda example: example['label'] in [0, 1])\n",
    "valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly select 10000 samples for the training set and 200 samples for the testing set\n",
    "sample_ds = {}\n",
    "sample_ds['train'] = ds['train'].shuffle(seed=42).select(range(10000))\n",
    "sample_ds['validation'] = ds['validation'].shuffle(seed=42).select(range(200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019b9f55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf4d3b5090941c6aabae425cc59b1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e0cec043a2452197a3ac96b0f7b432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90baaece89d4194a49075501cfc7c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae1deca2a964d91a76ac9afee0d633a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5974071150c47a08cd14e380840a532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load tokenizer and preprocess datasets\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['sentence'],truncation = True, padding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f25643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afbe1737ba248bea9f93bad1b455695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3845d739f9c44338dc9c9d43fed90a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'klein , charming in comedies like american pie and dead-on in election , ', 'label': 1, 'idx': 32326, 'input_ids': [74, 33663, 837, 23332, 287, 14577, 444, 588, 45630, 272, 2508, 290, 2636, 12, 261, 287, 3071, 837, 220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenized_ds = {}\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = sample_ds[split].map(preprocess_function, batched = True)\n",
    "print(tokenized_ds['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f8982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'covered earlier and much better ', 'label': 0, 'idx': 35226, 'input_ids': [32111, 2961, 290, 881, 1365, 220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'sentence': \"charles ' entertaining film chronicles seinfeld 's return to stand-up comedy after the wrap of his legendary sitcom , alongside wannabe comic adams ' attempts to get his shot at the big time . \", 'label': 1, 'idx': 426, 'input_ids': [10641, 829, 705, 17774, 2646, 16199, 2983, 384, 47187, 705, 82, 1441, 284, 1302, 12, 929, 10997, 706, 262, 14441, 286, 465, 13273, 37521, 837, 7848, 266, 1236, 11231, 9048, 512, 4105, 705, 6370, 284, 651, 465, 2823, 379, 262, 1263, 640, 764, 220, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_ds['train'][4])\n",
    "print(tokenized_ds['validation'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e38781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73298b53e6d64abe9d120d271b9aed76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#load and setup the pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'gpt2',\n",
    "    num_labels = 2,\n",
    "    id2label = {0:'negative',1:'positive'},\n",
    "    label2id = {'negative':0,'positive':1}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35a80d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "    return {'accuracy':(predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6df691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's pad token id to match the tokenizer's pad token id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dd9c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437f9571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7b6e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs = 1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\", # Evaluation is performed at the end of each epoch.\n",
    "    save_strategy=\"epoch\", # Model is saved at the end of each epoch.\n",
    "    load_best_model_at_end=True, # Load the best model at the end of training.\n",
    ")\n",
    "\n",
    "pre_trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_ds['train'],\n",
    "    eval_dataset = tokenized_ds['validation'],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90529c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.971271514892578, 'eval_accuracy': 0.465, 'eval_runtime': 1.6329, 'eval_samples_per_second': 122.482, 'eval_steps_per_second': 30.62}\n"
     ]
    }
   ],
   "source": [
    "pre_train_results = pre_trainer.evaluate()\n",
    "print(pre_train_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6e7ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05a9cbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('gpt2',\n",
    "                                                      num_labels=2,\n",
    "                                                      id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "                                                      label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb7f5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "894046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a peft config and model\n",
    "config = LoraConfig(\n",
    "        r = 4,\n",
    "        lora_alpha = 32,\n",
    "        lora_dropout = 0.1,\n",
    "        bias = 'none',\n",
    "        task_type = 'SEQ_CLS', #sequence_classification\n",
    "        target_modules=['c_attn', 'c_proj']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 408,576 || all params: 124,848,384 || trainable%: 0.3272577400761551\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(model, config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb355ebacaf54426ae636261c4a99fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383f4d4112ea4e108f276c45d72b59a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename 'label' to 'labels' \n",
    "tokenized_ds[\"train\"] = tokenized_ds[\"train\"].map(lambda x: {'labels': x['label']}, batched=True, remove_columns=['label'])\n",
    "tokenized_ds[\"validation\"] = tokenized_ds[\"validation\"].map(lambda x: {'labels': x['label']}, batched=True, remove_columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use trainer for the training loop\n",
    "training_args_lora = TrainingArguments(\n",
    "    output_dir = \"./lora_results\",\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs = 1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\", # Evaluation is performed at the end of each epoch.\n",
    "    save_strategy=\"epoch\", # Model is saved at the end of each epoch.\n",
    "    load_best_model_at_end=True, # Load the best model at the end of training.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = peft_model,\n",
    "    args = training_args_lora,\n",
    "    train_dataset = tokenized_ds['train'],\n",
    "    eval_dataset = tokenized_ds['validation'],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer,padding=True, max_length = 512),\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0734738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 03:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.500700</td>\n",
       "      <td>0.334081</td>\n",
       "      <td>0.885000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./lora_results/checkpoint-2500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.5711528198242187, metrics={'train_runtime': 191.8197, 'train_samples_per_second': 52.132, 'train_steps_per_second': 13.033, 'total_flos': 295010725736448.0, 'train_loss': 0.5711528198242187, 'epoch': 1.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the training process\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60789695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3340812623500824,\n",
       " 'eval_accuracy': 0.885,\n",
       " 'eval_runtime': 1.4024,\n",
       " 'eval_samples_per_second': 142.613,\n",
       " 'eval_steps_per_second': 35.653,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f901739",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained('gpt-lora')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForSequenceClassification\n",
    "\n",
    "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\"gpt-lora\", num_labels=2, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's pad token id to match the tokenizer's pad token id\n",
    "lora_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_lora = TrainingArguments(\n",
    "    output_dir = \"./inference\",\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs = 1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\", # Evaluation is performed at the end of each epoch.\n",
    "    save_strategy=\"epoch\", # Model is saved at the end of each epoch.\n",
    "    load_best_model_at_end=True, # Load the best model at the end of training.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_trainer = Trainer(\n",
    "    model=lora_model,  # The fine-tuned PEFT model.\n",
    "    args=training_args,# Training arguments, defined above.\n",
    "    train_dataset=tokenized_ds[\"train\"], # The tokenized training dataset.\n",
    "    eval_dataset=tokenized_ds[\"validation\"], # The tokenized evaluation dataset.\n",
    "    tokenizer=tokenizer, # The tokenizer used for encoding the data.\n",
    "    # Data collator that will dynamically pad the batches during training.\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics, # Function to compute metrics during evaluation.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for the fine-tuned model: {'eval_loss': 0.3340812623500824, 'eval_accuracy': 0.885, 'eval_runtime': 1.4577, 'eval_samples_per_second': 137.203, 'eval_steps_per_second': 34.301}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the fine-tuned model on the validation set\n",
    "finetuned_results = finetuned_trainer.evaluate()\n",
    "\n",
    "# Print the evaluation results for the fine-tuned model\n",
    "print(\"Evaluation results for the fine-tuned model:\", finetuned_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8f64a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the eval accuracy increased from 0.56 to \n",
    "#the eval loss decreased from 0.685"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
